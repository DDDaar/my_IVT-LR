project: ivtlr
save_path: /home/ma-user/work/lbx/IVT-LR/qwen_vl/output
name: m3cot_qwen2vl_IVTLR

# 添加数据集控制字段
dataset_name: scienceqa # 选项: 'scienceqa' 或 'scienceqa'
# --- [新增配置] ---
model_type: "2B"  # 选项: "2B" 或 "7B"
model_path_2b: "/home/ma-user/work/lbx/models/Qwen2-VL-2B-Instruct" # 请修改为实际2B模型路径
model_path_7b: "/home/ma-user/work/lbx/models/Qwen2-VL-7B-Instruct" # 请修改为实际7B模型路径
suffix: '_add_headfusion_mlp_head_gate(hidden_size, num_heads)_ste'

# -----------------
epochs_per_stage: 4
max_latent_stage: 5
pad_latent_to_max: True

load_model_path: None
seed: 0
resume: 0
bf16: True

# 原本是2,m3cot用的4，后面都用2吧？
batch_size_training: 2

debug: False
gradient_accumulation_steps: 8
num_epochs: 16
lr: !!float "4e-5"